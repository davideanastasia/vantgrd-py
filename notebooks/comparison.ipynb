{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vantgrd.logistic import LogisticRegressionFTRL, \\\n",
    "    LogisticRegressionWithAdagrad, LogisticRegressionWithAdadelta\n",
    "from vantgrd.fm import FMWithAdagrad, FMWithSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "\n",
    "X, y = datasets.make_classification(n_samples=200000, n_features=25,\n",
    "                                    n_informative=7, n_redundant=5, n_repeated=3,\n",
    "                                    random_state=42, weights=[0.92, 0.08])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "models = [\n",
    "    LogisticRegressionWithAdagrad(eta=.01, epochs=epochs, rate=1000),\n",
    "    LogisticRegressionWithAdadelta(epochs=epochs, rate=1000),\n",
    "    LogisticRegressionFTRL(epochs=epochs, rate=1000),\n",
    "    FMWithAdagrad(eta=0.01, reg0=.01, regw=.01, regv=.01, rate=1000, epochs=epochs, n_factors=5),\n",
    "    FMWithSGD(eta=0.01, reg0=.01, regw=.01, regv=.01, rate=1000, epochs=epochs, n_factors=5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {0: 'blue', 1: 'red', 2: 'black', 3: 'green', 4: 'yellow'}\n",
    "labels = {0: 'lr-adagrad', 1: 'lr-adadelta', 2: 'lr-ftrl', 3: 'fm-adagrad', 4: 'fm-sgd'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Training Samples:      1000 | Loss:      470.72 | LossAdj:  0.47072 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      2000 | Loss:      887.01 | LossAdj:  0.44350 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      3000 | Loss:     1279.41 | LossAdj:  0.42647 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      4000 | Loss:     1665.92 | LossAdj:  0.41648 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      5000 | Loss:     2025.61 | LossAdj:  0.40512 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      6000 | Loss:     2388.46 | LossAdj:  0.39808 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      7000 | Loss:     2756.16 | LossAdj:  0.39374 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      8000 | Loss:     3101.86 | LossAdj:  0.38773 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      9000 | Loss:     3483.62 | LossAdj:  0.38707 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:     10000 | Loss:     3837.15 | LossAdj:  0.38371 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:     11000 | Loss:     4189.33 | LossAdj:  0.38085 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:     12000 | Loss:     4550.31 | LossAdj:  0.37919 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:     13000 | Loss:     4887.99 | LossAdj:  0.37600 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:     14000 | Loss:     5238.20 | LossAdj:  0.37416 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:     15000 | Loss:     5591.28 | LossAdj:  0.37275 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:     16000 | Loss:     5928.90 | LossAdj:  0.37056 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:     17000 | Loss:     6261.83 | LossAdj:  0.36834 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:     18000 | Loss:     6608.72 | LossAdj:  0.36715 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     19000 | Loss:     6962.23 | LossAdj:  0.36643 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     20000 | Loss:     7309.24 | LossAdj:  0.36546 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     21000 | Loss:     7647.64 | LossAdj:  0.36417 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     22000 | Loss:     7999.27 | LossAdj:  0.36360 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     23000 | Loss:     8348.37 | LossAdj:  0.36297 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     24000 | Loss:     8671.81 | LossAdj:  0.36133 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     25000 | Loss:     9001.01 | LossAdj:  0.36004 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     26000 | Loss:     9365.67 | LossAdj:  0.36022 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     27000 | Loss:     9704.38 | LossAdj:  0.35942 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     28000 | Loss:    10045.72 | LossAdj:  0.35878 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     29000 | Loss:    10388.37 | LossAdj:  0.35822 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     30000 | Loss:    10744.64 | LossAdj:  0.35815 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     31000 | Loss:    11103.24 | LossAdj:  0.35817 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     32000 | Loss:    11434.73 | LossAdj:  0.35734 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     33000 | Loss:    11772.02 | LossAdj:  0.35673 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     34000 | Loss:    12099.72 | LossAdj:  0.35587 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     35000 | Loss:    12421.56 | LossAdj:  0.35490 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     36000 | Loss:    12775.38 | LossAdj:  0.35487 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     37000 | Loss:    13082.44 | LossAdj:  0.35358 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     38000 | Loss:    13395.14 | LossAdj:  0.35250 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     39000 | Loss:    13726.41 | LossAdj:  0.35196 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     40000 | Loss:    14070.23 | LossAdj:  0.35176 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     41000 | Loss:    14405.91 | LossAdj:  0.35136 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     42000 | Loss:    14739.10 | LossAdj:  0.35093 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     43000 | Loss:    15080.39 | LossAdj:  0.35071 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     44000 | Loss:    15420.61 | LossAdj:  0.35047 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     45000 | Loss:    15746.40 | LossAdj:  0.34992 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     46000 | Loss:    16077.22 | LossAdj:  0.34950 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     47000 | Loss:    16413.14 | LossAdj:  0.34922 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     48000 | Loss:    16745.00 | LossAdj:  0.34885 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     49000 | Loss:    17084.91 | LossAdj:  0.34867 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     50000 | Loss:    17403.51 | LossAdj:  0.34807 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     51000 | Loss:    17742.75 | LossAdj:  0.34790 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     52000 | Loss:    18083.85 | LossAdj:  0.34777 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     53000 | Loss:    18402.10 | LossAdj:  0.34721 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     54000 | Loss:    18735.51 | LossAdj:  0.34695 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     55000 | Loss:    19067.36 | LossAdj:  0.34668 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     56000 | Loss:    19390.04 | LossAdj:  0.34625 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     57000 | Loss:    19740.23 | LossAdj:  0.34632 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     58000 | Loss:    20087.49 | LossAdj:  0.34634 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     59000 | Loss:    20419.64 | LossAdj:  0.34610 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     60000 | Loss:    20761.32 | LossAdj:  0.34602 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     61000 | Loss:    21085.56 | LossAdj:  0.34566 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     62000 | Loss:    21404.26 | LossAdj:  0.34523 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     63000 | Loss:    21739.67 | LossAdj:  0.34507 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     64000 | Loss:    22046.69 | LossAdj:  0.34448 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     65000 | Loss:    22372.83 | LossAdj:  0.34420 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     66000 | Loss:    22676.00 | LossAdj:  0.34358 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     67000 | Loss:    23010.78 | LossAdj:  0.34344 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     68000 | Loss:    23333.86 | LossAdj:  0.34315 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     69000 | Loss:    23660.18 | LossAdj:  0.34290 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     70000 | Loss:    23966.86 | LossAdj:  0.34238 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     71000 | Loss:    24295.49 | LossAdj:  0.34219 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     72000 | Loss:    24613.06 | LossAdj:  0.34185 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     73000 | Loss:    24919.90 | LossAdj:  0.34137 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     74000 | Loss:    25223.00 | LossAdj:  0.34085 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     75000 | Loss:    25537.77 | LossAdj:  0.34050 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     76000 | Loss:    25880.14 | LossAdj:  0.34053 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     77000 | Loss:    26206.60 | LossAdj:  0.34035 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     78000 | Loss:    26545.99 | LossAdj:  0.34033 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     79000 | Loss:    26862.26 | LossAdj:  0.34003 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     80000 | Loss:    27196.44 | LossAdj:  0.33996 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     81000 | Loss:    27538.10 | LossAdj:  0.33998 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     82000 | Loss:    27872.81 | LossAdj:  0.33991 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     83000 | Loss:    28214.18 | LossAdj:  0.33993 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     84000 | Loss:    28545.62 | LossAdj:  0.33983 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     85000 | Loss:    28855.19 | LossAdj:  0.33947 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     86000 | Loss:    29199.64 | LossAdj:  0.33953 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     87000 | Loss:    29541.74 | LossAdj:  0.33956 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     88000 | Loss:    29873.75 | LossAdj:  0.33947 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     89000 | Loss:    30180.09 | LossAdj:  0.33910 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     90000 | Loss:    30497.45 | LossAdj:  0.33886 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     91000 | Loss:    30842.46 | LossAdj:  0.33893 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     92000 | Loss:    31184.71 | LossAdj:  0.33896 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     93000 | Loss:    31482.70 | LossAdj:  0.33852 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     94000 | Loss:    31823.68 | LossAdj:  0.33855 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     95000 | Loss:    32143.73 | LossAdj:  0.33836 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:     96000 | Loss:    32468.74 | LossAdj:  0.33822 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:     97000 | Loss:    32785.78 | LossAdj:  0.33800 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:     98000 | Loss:    33098.98 | LossAdj:  0.33774 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:     99000 | Loss:    33438.79 | LossAdj:  0.33777 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:    100000 | Loss:    33771.45 | LossAdj:  0.33771 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:    101000 | Loss:    34094.00 | LossAdj:  0.33756 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:    102000 | Loss:    34416.90 | LossAdj:  0.33742 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:    103000 | Loss:    34754.25 | LossAdj:  0.33742 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:    104000 | Loss:    35063.61 | LossAdj:  0.33715 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:    105000 | Loss:    35395.20 | LossAdj:  0.33710 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:    106000 | Loss:    35735.43 | LossAdj:  0.33713 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:    107000 | Loss:    36050.06 | LossAdj:  0.33692 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:    108000 | Loss:    36355.68 | LossAdj:  0.33663 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:    109000 | Loss:    36682.73 | LossAdj:  0.33654 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:    110000 | Loss:    37012.32 | LossAdj:  0.33648 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:    111000 | Loss:    37337.16 | LossAdj:  0.33637 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:    112000 | Loss:    37654.82 | LossAdj:  0.33620 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:    113000 | Loss:    37974.46 | LossAdj:  0.33606 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:    114000 | Loss:    38306.67 | LossAdj:  0.33602 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:    115000 | Loss:    38627.66 | LossAdj:  0.33589 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:    116000 | Loss:    38946.93 | LossAdj:  0.33575 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:    117000 | Loss:    39283.28 | LossAdj:  0.33575 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:    118000 | Loss:    39603.88 | LossAdj:  0.33563 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:    119000 | Loss:    39928.25 | LossAdj:  0.33553 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:    120000 | Loss:    40274.44 | LossAdj:  0.33562 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:    121000 | Loss:    40609.30 | LossAdj:  0.33561 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    122000 | Loss:    40941.98 | LossAdj:  0.33559 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    123000 | Loss:    41249.06 | LossAdj:  0.33536 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    124000 | Loss:    41601.13 | LossAdj:  0.33549 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    125000 | Loss:    41919.35 | LossAdj:  0.33535 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    126000 | Loss:    42244.57 | LossAdj:  0.33527 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:    127000 | Loss:    42572.57 | LossAdj:  0.33522 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:    128000 | Loss:    42872.83 | LossAdj:  0.33494 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:    129000 | Loss:    43168.19 | LossAdj:  0.33464 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:    130000 | Loss:    43475.67 | LossAdj:  0.33443 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:    131000 | Loss:    43792.90 | LossAdj:  0.33430 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:    132000 | Loss:    44119.77 | LossAdj:  0.33424 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:    133000 | Loss:    44440.39 | LossAdj:  0.33414 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:    134000 | Loss:    44773.24 | LossAdj:  0.33413 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:    135000 | Loss:    45113.47 | LossAdj:  0.33417 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:    136000 | Loss:    45432.50 | LossAdj:  0.33406 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:    137000 | Loss:    45762.35 | LossAdj:  0.33403 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:    138000 | Loss:    46058.09 | LossAdj:  0.33375 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:    139000 | Loss:    46355.22 | LossAdj:  0.33349 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:    140000 | Loss:    46671.31 | LossAdj:  0.33337 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:    141000 | Loss:    46983.53 | LossAdj:  0.33322 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:    142000 | Loss:    47303.58 | LossAdj:  0.33312 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:    143000 | Loss:    47625.97 | LossAdj:  0.33305 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:    144000 | Loss:    47932.16 | LossAdj:  0.33286 | Time taken:   32 seconds\n",
      "Epoch:   0 | Training Samples:    145000 | Loss:    48235.09 | LossAdj:  0.33266 | Time taken:   32 seconds\n",
      "Epoch:   0 | Training Samples:    146000 | Loss:    48575.04 | LossAdj:  0.33271 | Time taken:   32 seconds\n",
      "Epoch:   0 | Training Samples:    147000 | Loss:    48897.69 | LossAdj:  0.33264 | Time taken:   32 seconds\n",
      "Epoch:   0 | Training Samples:    148000 | Loss:    49233.54 | LossAdj:  0.33266 | Time taken:   33 seconds\n",
      "Epoch:   0 | Training Samples:    149000 | Loss:    49562.70 | LossAdj:  0.33264 | Time taken:   33 seconds\n",
      "Epoch:   0 | Training Samples:    150000 | Loss:    49892.19 | LossAdj:  0.33261 | Time taken:   33 seconds\n",
      " --- TRAINING FINISHED IN 33 SECONDS WITH LOSS 0.33 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93     45786\n",
      "           1       0.38      0.72      0.50      4214\n",
      "\n",
      "    accuracy                           0.88     50000\n",
      "   macro avg       0.68      0.81      0.71     50000\n",
      "weighted avg       0.92      0.88      0.89     50000\n",
      "\n",
      "AUC = 0.895150\n",
      "Epoch:   0 | Training Samples:      1000 | Loss:      573.45 | LossAdj:  0.57345 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      2000 | Loss:     1052.40 | LossAdj:  0.52620 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      3000 | Loss:     1480.65 | LossAdj:  0.49355 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      4000 | Loss:     1860.74 | LossAdj:  0.46519 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      5000 | Loss:     2200.74 | LossAdj:  0.44015 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      6000 | Loss:     2508.19 | LossAdj:  0.41803 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      7000 | Loss:     2796.02 | LossAdj:  0.39943 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      8000 | Loss:     3051.23 | LossAdj:  0.38140 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      9000 | Loss:     3332.85 | LossAdj:  0.37032 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:     10000 | Loss:     3594.76 | LossAdj:  0.35948 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:     11000 | Loss:     3852.40 | LossAdj:  0.35022 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:     12000 | Loss:     4104.73 | LossAdj:  0.34206 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:     13000 | Loss:     4344.82 | LossAdj:  0.33422 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:     14000 | Loss:     4589.11 | LossAdj:  0.32779 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:     15000 | Loss:     4821.60 | LossAdj:  0.32144 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:     16000 | Loss:     5062.84 | LossAdj:  0.31643 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:     17000 | Loss:     5295.81 | LossAdj:  0.31152 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:     18000 | Loss:     5536.61 | LossAdj:  0.30759 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     19000 | Loss:     5800.74 | LossAdj:  0.30530 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     20000 | Loss:     6037.36 | LossAdj:  0.30187 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     21000 | Loss:     6295.87 | LossAdj:  0.29980 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     22000 | Loss:     6535.33 | LossAdj:  0.29706 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     23000 | Loss:     6756.56 | LossAdj:  0.29376 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     24000 | Loss:     7006.79 | LossAdj:  0.29195 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     25000 | Loss:     7226.08 | LossAdj:  0.28904 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     26000 | Loss:     7466.81 | LossAdj:  0.28718 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     27000 | Loss:     7709.35 | LossAdj:  0.28553 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     28000 | Loss:     7938.90 | LossAdj:  0.28353 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     29000 | Loss:     8164.53 | LossAdj:  0.28154 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     30000 | Loss:     8421.96 | LossAdj:  0.28073 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     31000 | Loss:     8671.44 | LossAdj:  0.27972 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     32000 | Loss:     8912.28 | LossAdj:  0.27851 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     33000 | Loss:     9128.50 | LossAdj:  0.27662 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     34000 | Loss:     9365.36 | LossAdj:  0.27545 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     35000 | Loss:     9575.84 | LossAdj:  0.27360 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     36000 | Loss:     9829.03 | LossAdj:  0.27303 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     37000 | Loss:    10030.71 | LossAdj:  0.27110 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     38000 | Loss:    10258.56 | LossAdj:  0.26996 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     39000 | Loss:    10489.83 | LossAdj:  0.26897 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     40000 | Loss:    10716.04 | LossAdj:  0.26790 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     41000 | Loss:    10933.79 | LossAdj:  0.26668 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     42000 | Loss:    11136.03 | LossAdj:  0.26514 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     43000 | Loss:    11360.49 | LossAdj:  0.26420 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     44000 | Loss:    11582.47 | LossAdj:  0.26324 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     45000 | Loss:    11795.96 | LossAdj:  0.26213 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     46000 | Loss:    12039.98 | LossAdj:  0.26174 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     47000 | Loss:    12249.80 | LossAdj:  0.26063 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     48000 | Loss:    12495.84 | LossAdj:  0.26033 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     49000 | Loss:    12711.04 | LossAdj:  0.25941 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     50000 | Loss:    12910.48 | LossAdj:  0.25821 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     51000 | Loss:    13110.62 | LossAdj:  0.25707 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     52000 | Loss:    13318.30 | LossAdj:  0.25612 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     53000 | Loss:    13515.30 | LossAdj:  0.25501 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     54000 | Loss:    13752.30 | LossAdj:  0.25467 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     55000 | Loss:    13950.51 | LossAdj:  0.25365 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     56000 | Loss:    14177.63 | LossAdj:  0.25317 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     57000 | Loss:    14414.37 | LossAdj:  0.25288 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     58000 | Loss:    14639.61 | LossAdj:  0.25241 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     59000 | Loss:    14831.95 | LossAdj:  0.25139 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     60000 | Loss:    15019.63 | LossAdj:  0.25033 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     61000 | Loss:    15210.39 | LossAdj:  0.24935 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     62000 | Loss:    15417.17 | LossAdj:  0.24866 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     63000 | Loss:    15639.59 | LossAdj:  0.24825 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     64000 | Loss:    15844.09 | LossAdj:  0.24756 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     65000 | Loss:    16041.35 | LossAdj:  0.24679 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     66000 | Loss:    16223.59 | LossAdj:  0.24581 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     67000 | Loss:    16429.62 | LossAdj:  0.24522 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     68000 | Loss:    16640.48 | LossAdj:  0.24471 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     69000 | Loss:    16853.01 | LossAdj:  0.24425 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     70000 | Loss:    17075.29 | LossAdj:  0.24393 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     71000 | Loss:    17294.03 | LossAdj:  0.24358 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     72000 | Loss:    17507.40 | LossAdj:  0.24316 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     73000 | Loss:    17720.44 | LossAdj:  0.24275 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     74000 | Loss:    17939.96 | LossAdj:  0.24243 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     75000 | Loss:    18189.16 | LossAdj:  0.24252 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     76000 | Loss:    18392.08 | LossAdj:  0.24200 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     77000 | Loss:    18607.25 | LossAdj:  0.24165 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     78000 | Loss:    18806.09 | LossAdj:  0.24110 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     79000 | Loss:    19016.91 | LossAdj:  0.24072 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     80000 | Loss:    19242.32 | LossAdj:  0.24053 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     81000 | Loss:    19460.39 | LossAdj:  0.24025 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     82000 | Loss:    19696.29 | LossAdj:  0.24020 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     83000 | Loss:    19916.44 | LossAdj:  0.23996 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     84000 | Loss:    20155.78 | LossAdj:  0.23995 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     85000 | Loss:    20386.03 | LossAdj:  0.23984 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     86000 | Loss:    20616.06 | LossAdj:  0.23972 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     87000 | Loss:    20834.22 | LossAdj:  0.23947 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     88000 | Loss:    21050.58 | LossAdj:  0.23921 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     89000 | Loss:    21217.89 | LossAdj:  0.23840 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     90000 | Loss:    21405.14 | LossAdj:  0.23783 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     91000 | Loss:    21626.20 | LossAdj:  0.23765 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     92000 | Loss:    21858.53 | LossAdj:  0.23759 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     93000 | Loss:    22069.67 | LossAdj:  0.23731 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     94000 | Loss:    22279.68 | LossAdj:  0.23702 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:     95000 | Loss:    22501.58 | LossAdj:  0.23686 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:     96000 | Loss:    22743.99 | LossAdj:  0.23692 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:     97000 | Loss:    22936.44 | LossAdj:  0.23646 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:     98000 | Loss:    23175.67 | LossAdj:  0.23649 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:     99000 | Loss:    23375.34 | LossAdj:  0.23611 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:    100000 | Loss:    23601.83 | LossAdj:  0.23602 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:    101000 | Loss:    23809.16 | LossAdj:  0.23573 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:    102000 | Loss:    23982.66 | LossAdj:  0.23512 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:    103000 | Loss:    24204.59 | LossAdj:  0.23500 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:    104000 | Loss:    24402.49 | LossAdj:  0.23464 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:    105000 | Loss:    24630.39 | LossAdj:  0.23458 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:    106000 | Loss:    24795.04 | LossAdj:  0.23392 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:    107000 | Loss:    25011.06 | LossAdj:  0.23375 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:    108000 | Loss:    25235.32 | LossAdj:  0.23366 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:    109000 | Loss:    25449.76 | LossAdj:  0.23348 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:    110000 | Loss:    25627.35 | LossAdj:  0.23298 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:    111000 | Loss:    25850.50 | LossAdj:  0.23289 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:    112000 | Loss:    26057.97 | LossAdj:  0.23266 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:    113000 | Loss:    26260.82 | LossAdj:  0.23240 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:    114000 | Loss:    26485.64 | LossAdj:  0.23233 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:    115000 | Loss:    26676.44 | LossAdj:  0.23197 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:    116000 | Loss:    26887.05 | LossAdj:  0.23178 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:    117000 | Loss:    27073.44 | LossAdj:  0.23140 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:    118000 | Loss:    27308.63 | LossAdj:  0.23143 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:    119000 | Loss:    27538.91 | LossAdj:  0.23142 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:    120000 | Loss:    27760.00 | LossAdj:  0.23133 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:    121000 | Loss:    27967.90 | LossAdj:  0.23114 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    122000 | Loss:    28166.33 | LossAdj:  0.23087 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    123000 | Loss:    28359.42 | LossAdj:  0.23056 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    124000 | Loss:    28574.40 | LossAdj:  0.23044 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    125000 | Loss:    28788.24 | LossAdj:  0.23031 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    126000 | Loss:    28976.51 | LossAdj:  0.22997 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:    127000 | Loss:    29204.45 | LossAdj:  0.22996 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:    128000 | Loss:    29413.85 | LossAdj:  0.22980 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:    129000 | Loss:    29624.33 | LossAdj:  0.22965 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:    130000 | Loss:    29825.74 | LossAdj:  0.22943 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:    131000 | Loss:    29995.28 | LossAdj:  0.22897 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:    132000 | Loss:    30179.85 | LossAdj:  0.22864 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:    133000 | Loss:    30418.59 | LossAdj:  0.22871 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:    134000 | Loss:    30629.00 | LossAdj:  0.22857 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:    135000 | Loss:    30831.80 | LossAdj:  0.22838 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:    136000 | Loss:    31027.20 | LossAdj:  0.22814 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:    137000 | Loss:    31248.52 | LossAdj:  0.22809 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:    138000 | Loss:    31443.67 | LossAdj:  0.22785 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:    139000 | Loss:    31679.40 | LossAdj:  0.22791 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:    140000 | Loss:    31873.79 | LossAdj:  0.22767 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:    141000 | Loss:    32109.59 | LossAdj:  0.22773 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:    142000 | Loss:    32296.49 | LossAdj:  0.22744 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:    143000 | Loss:    32513.48 | LossAdj:  0.22737 | Time taken:   32 seconds\n",
      "Epoch:   0 | Training Samples:    144000 | Loss:    32734.63 | LossAdj:  0.22732 | Time taken:   32 seconds\n",
      "Epoch:   0 | Training Samples:    145000 | Loss:    32925.14 | LossAdj:  0.22707 | Time taken:   32 seconds\n",
      "Epoch:   0 | Training Samples:    146000 | Loss:    33115.58 | LossAdj:  0.22682 | Time taken:   32 seconds\n",
      "Epoch:   0 | Training Samples:    147000 | Loss:    33338.74 | LossAdj:  0.22679 | Time taken:   33 seconds\n",
      "Epoch:   0 | Training Samples:    148000 | Loss:    33549.00 | LossAdj:  0.22668 | Time taken:   33 seconds\n",
      "Epoch:   0 | Training Samples:    149000 | Loss:    33746.69 | LossAdj:  0.22649 | Time taken:   33 seconds\n",
      "Epoch:   0 | Training Samples:    150000 | Loss:    33978.04 | LossAdj:  0.22652 | Time taken:   33 seconds\n",
      " --- TRAINING FINISHED IN 33 SECONDS WITH LOSS 0.23 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     45786\n",
      "           1       0.55      0.63      0.59      4214\n",
      "\n",
      "    accuracy                           0.93     50000\n",
      "   macro avg       0.76      0.79      0.77     50000\n",
      "weighted avg       0.93      0.93      0.93     50000\n",
      "\n",
      "AUC = 0.902750\n",
      "Epoch:   0 | Training Samples:      1000 | Loss:      429.08 | LossAdj:  0.42908 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      2000 | Loss:      788.95 | LossAdj:  0.39448 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      3000 | Loss:     1157.35 | LossAdj:  0.38578 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      4000 | Loss:     1479.28 | LossAdj:  0.36982 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      5000 | Loss:     1805.41 | LossAdj:  0.36108 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      6000 | Loss:     2135.81 | LossAdj:  0.35597 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      7000 | Loss:     2488.75 | LossAdj:  0.35554 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      8000 | Loss:     2812.27 | LossAdj:  0.35153 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      9000 | Loss:     3134.12 | LossAdj:  0.34824 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:     10000 | Loss:     3467.09 | LossAdj:  0.34671 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:     11000 | Loss:     3786.86 | LossAdj:  0.34426 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:     12000 | Loss:     4078.00 | LossAdj:  0.33983 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:     13000 | Loss:     4413.44 | LossAdj:  0.33950 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:     14000 | Loss:     4751.29 | LossAdj:  0.33938 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:     15000 | Loss:     5111.37 | LossAdj:  0.34076 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:     16000 | Loss:     5435.62 | LossAdj:  0.33973 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:     17000 | Loss:     5756.48 | LossAdj:  0.33862 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:     18000 | Loss:     6079.64 | LossAdj:  0.33776 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:     19000 | Loss:     6398.83 | LossAdj:  0.33678 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     20000 | Loss:     6729.96 | LossAdj:  0.33650 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     21000 | Loss:     7067.80 | LossAdj:  0.33656 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     22000 | Loss:     7378.98 | LossAdj:  0.33541 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     23000 | Loss:     7674.94 | LossAdj:  0.33369 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     24000 | Loss:     7962.76 | LossAdj:  0.33178 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     25000 | Loss:     8281.98 | LossAdj:  0.33128 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     26000 | Loss:     8581.04 | LossAdj:  0.33004 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     27000 | Loss:     8898.03 | LossAdj:  0.32956 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     28000 | Loss:     9240.10 | LossAdj:  0.33000 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     29000 | Loss:     9568.43 | LossAdj:  0.32995 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     30000 | Loss:     9877.80 | LossAdj:  0.32926 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     31000 | Loss:    10166.29 | LossAdj:  0.32794 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     32000 | Loss:    10511.15 | LossAdj:  0.32847 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     33000 | Loss:    10823.15 | LossAdj:  0.32797 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     34000 | Loss:    11143.79 | LossAdj:  0.32776 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     35000 | Loss:    11452.11 | LossAdj:  0.32720 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     36000 | Loss:    11768.27 | LossAdj:  0.32690 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     37000 | Loss:    12077.75 | LossAdj:  0.32643 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     38000 | Loss:    12398.41 | LossAdj:  0.32627 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     39000 | Loss:    12691.67 | LossAdj:  0.32543 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     40000 | Loss:    12975.49 | LossAdj:  0.32439 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     41000 | Loss:    13277.92 | LossAdj:  0.32385 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     42000 | Loss:    13605.36 | LossAdj:  0.32394 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     43000 | Loss:    13926.96 | LossAdj:  0.32388 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     44000 | Loss:    14240.99 | LossAdj:  0.32366 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     45000 | Loss:    14558.51 | LossAdj:  0.32352 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     46000 | Loss:    14889.84 | LossAdj:  0.32369 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     47000 | Loss:    15181.13 | LossAdj:  0.32300 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     48000 | Loss:    15504.28 | LossAdj:  0.32301 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     49000 | Loss:    15796.08 | LossAdj:  0.32237 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     50000 | Loss:    16095.93 | LossAdj:  0.32192 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     51000 | Loss:    16355.95 | LossAdj:  0.32070 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     52000 | Loss:    16652.06 | LossAdj:  0.32023 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     53000 | Loss:    16943.38 | LossAdj:  0.31969 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     54000 | Loss:    17243.89 | LossAdj:  0.31933 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     55000 | Loss:    17532.29 | LossAdj:  0.31877 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     56000 | Loss:    17845.78 | LossAdj:  0.31867 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     57000 | Loss:    18178.84 | LossAdj:  0.31893 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     58000 | Loss:    18477.71 | LossAdj:  0.31858 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     59000 | Loss:    18800.70 | LossAdj:  0.31866 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     60000 | Loss:    19124.40 | LossAdj:  0.31874 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     61000 | Loss:    19422.69 | LossAdj:  0.31840 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     62000 | Loss:    19736.06 | LossAdj:  0.31832 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     63000 | Loss:    20063.13 | LossAdj:  0.31846 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     64000 | Loss:    20373.58 | LossAdj:  0.31834 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     65000 | Loss:    20679.33 | LossAdj:  0.31814 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     66000 | Loss:    20988.07 | LossAdj:  0.31800 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     67000 | Loss:    21318.62 | LossAdj:  0.31819 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     68000 | Loss:    21616.23 | LossAdj:  0.31789 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     69000 | Loss:    21934.97 | LossAdj:  0.31790 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     70000 | Loss:    22262.20 | LossAdj:  0.31803 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     71000 | Loss:    22577.80 | LossAdj:  0.31800 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     72000 | Loss:    22889.76 | LossAdj:  0.31791 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     73000 | Loss:    23204.05 | LossAdj:  0.31786 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     74000 | Loss:    23525.44 | LossAdj:  0.31791 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     75000 | Loss:    23834.34 | LossAdj:  0.31779 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     76000 | Loss:    24148.53 | LossAdj:  0.31774 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     77000 | Loss:    24482.28 | LossAdj:  0.31795 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     78000 | Loss:    24776.62 | LossAdj:  0.31765 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     79000 | Loss:    25074.03 | LossAdj:  0.31739 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     80000 | Loss:    25387.24 | LossAdj:  0.31734 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     81000 | Loss:    25684.22 | LossAdj:  0.31709 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     82000 | Loss:    25979.97 | LossAdj:  0.31683 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     83000 | Loss:    26286.78 | LossAdj:  0.31671 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     84000 | Loss:    26609.69 | LossAdj:  0.31678 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     85000 | Loss:    26927.31 | LossAdj:  0.31679 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     86000 | Loss:    27233.99 | LossAdj:  0.31667 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     87000 | Loss:    27546.79 | LossAdj:  0.31663 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     88000 | Loss:    27868.15 | LossAdj:  0.31668 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     89000 | Loss:    28174.47 | LossAdj:  0.31657 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     90000 | Loss:    28490.26 | LossAdj:  0.31656 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     91000 | Loss:    28807.77 | LossAdj:  0.31657 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     92000 | Loss:    29132.45 | LossAdj:  0.31666 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     93000 | Loss:    29461.66 | LossAdj:  0.31679 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     94000 | Loss:    29770.68 | LossAdj:  0.31671 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     95000 | Loss:    30087.02 | LossAdj:  0.31671 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     96000 | Loss:    30402.71 | LossAdj:  0.31669 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     97000 | Loss:    30704.91 | LossAdj:  0.31655 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     98000 | Loss:    31015.24 | LossAdj:  0.31648 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:     99000 | Loss:    31319.42 | LossAdj:  0.31636 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:    100000 | Loss:    31641.37 | LossAdj:  0.31641 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:    101000 | Loss:    31956.02 | LossAdj:  0.31640 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:    102000 | Loss:    32263.43 | LossAdj:  0.31631 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:    103000 | Loss:    32573.02 | LossAdj:  0.31624 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:    104000 | Loss:    32883.38 | LossAdj:  0.31619 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:    105000 | Loss:    33174.57 | LossAdj:  0.31595 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:    106000 | Loss:    33476.43 | LossAdj:  0.31582 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:    107000 | Loss:    33779.68 | LossAdj:  0.31570 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:    108000 | Loss:    34078.84 | LossAdj:  0.31554 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:    109000 | Loss:    34390.37 | LossAdj:  0.31551 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:    110000 | Loss:    34695.78 | LossAdj:  0.31542 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:    111000 | Loss:    34952.37 | LossAdj:  0.31489 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:    112000 | Loss:    35258.84 | LossAdj:  0.31481 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:    113000 | Loss:    35562.57 | LossAdj:  0.31471 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:    114000 | Loss:    35861.13 | LossAdj:  0.31457 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:    115000 | Loss:    36165.19 | LossAdj:  0.31448 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:    116000 | Loss:    36487.19 | LossAdj:  0.31454 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:    117000 | Loss:    36786.02 | LossAdj:  0.31441 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:    118000 | Loss:    37107.41 | LossAdj:  0.31447 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:    119000 | Loss:    37415.51 | LossAdj:  0.31442 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:    120000 | Loss:    37727.66 | LossAdj:  0.31440 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:    121000 | Loss:    38070.43 | LossAdj:  0.31463 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:    122000 | Loss:    38374.85 | LossAdj:  0.31455 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:    123000 | Loss:    38681.90 | LossAdj:  0.31449 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:    124000 | Loss:    38974.23 | LossAdj:  0.31431 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:    125000 | Loss:    39277.32 | LossAdj:  0.31422 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    126000 | Loss:    39562.93 | LossAdj:  0.31399 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    127000 | Loss:    39889.18 | LossAdj:  0.31409 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    128000 | Loss:    40179.66 | LossAdj:  0.31390 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    129000 | Loss:    40512.26 | LossAdj:  0.31405 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:    130000 | Loss:    40818.22 | LossAdj:  0.31399 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:    131000 | Loss:    41110.86 | LossAdj:  0.31382 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:    132000 | Loss:    41420.47 | LossAdj:  0.31379 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:    133000 | Loss:    41740.01 | LossAdj:  0.31383 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:    134000 | Loss:    42038.69 | LossAdj:  0.31372 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:    135000 | Loss:    42348.12 | LossAdj:  0.31369 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:    136000 | Loss:    42648.81 | LossAdj:  0.31359 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:    137000 | Loss:    42933.91 | LossAdj:  0.31339 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:    138000 | Loss:    43236.28 | LossAdj:  0.31331 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:    139000 | Loss:    43523.81 | LossAdj:  0.31312 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:    140000 | Loss:    43813.86 | LossAdj:  0.31296 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:    141000 | Loss:    44109.54 | LossAdj:  0.31283 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:    142000 | Loss:    44400.47 | LossAdj:  0.31268 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:    143000 | Loss:    44712.03 | LossAdj:  0.31267 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:    144000 | Loss:    45030.82 | LossAdj:  0.31271 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:    145000 | Loss:    45318.77 | LossAdj:  0.31254 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:    146000 | Loss:    45651.16 | LossAdj:  0.31268 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:    147000 | Loss:    45978.55 | LossAdj:  0.31278 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:    148000 | Loss:    46277.01 | LossAdj:  0.31268 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:    149000 | Loss:    46577.75 | LossAdj:  0.31260 | Time taken:   32 seconds\n",
      "Epoch:   0 | Training Samples:    150000 | Loss:    46878.62 | LossAdj:  0.31252 | Time taken:   32 seconds\n",
      " --- TRAINING FINISHED IN 32 SECONDS WITH LOSS 0.31 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93     45786\n",
      "           1       0.39      0.72      0.51      4214\n",
      "\n",
      "    accuracy                           0.88     50000\n",
      "   macro avg       0.68      0.81      0.72     50000\n",
      "weighted avg       0.92      0.88      0.90     50000\n",
      "\n",
      "AUC = 0.896821\n",
      "Epoch:   0 | Training Samples:      1000 | Loss:     1163.22 | LossAdj:  1.16322 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      2000 | Loss:     2053.44 | LossAdj:  1.02672 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      3000 | Loss:     2663.24 | LossAdj:  0.88775 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      4000 | Loss:     3286.72 | LossAdj:  0.82168 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:      5000 | Loss:     3864.88 | LossAdj:  0.77298 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:      6000 | Loss:     4526.01 | LossAdj:  0.75434 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:      7000 | Loss:     5291.94 | LossAdj:  0.75599 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:      8000 | Loss:     5929.73 | LossAdj:  0.74122 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:      9000 | Loss:     6483.85 | LossAdj:  0.72043 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     10000 | Loss:     6974.19 | LossAdj:  0.69742 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     11000 | Loss:     7289.89 | LossAdj:  0.66272 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     12000 | Loss:     7636.15 | LossAdj:  0.63635 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     13000 | Loss:     8277.91 | LossAdj:  0.63676 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     14000 | Loss:     8882.99 | LossAdj:  0.63450 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     15000 | Loss:     9368.03 | LossAdj:  0.62454 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     16000 | Loss:     9776.12 | LossAdj:  0.61101 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     17000 | Loss:    10064.15 | LossAdj:  0.59201 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     18000 | Loss:    10708.52 | LossAdj:  0.59492 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     19000 | Loss:    11127.11 | LossAdj:  0.58564 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     20000 | Loss:    11731.54 | LossAdj:  0.58658 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     21000 | Loss:    12354.85 | LossAdj:  0.58833 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     22000 | Loss:    12870.19 | LossAdj:  0.58501 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     23000 | Loss:    13204.10 | LossAdj:  0.57409 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     24000 | Loss:    13665.48 | LossAdj:  0.56939 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     25000 | Loss:    14295.83 | LossAdj:  0.57183 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     26000 | Loss:    14782.59 | LossAdj:  0.56856 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     27000 | Loss:    15339.88 | LossAdj:  0.56814 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     28000 | Loss:    15649.23 | LossAdj:  0.55890 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     29000 | Loss:    16180.84 | LossAdj:  0.55796 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     30000 | Loss:    16665.69 | LossAdj:  0.55552 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     31000 | Loss:    17067.87 | LossAdj:  0.55058 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     32000 | Loss:    17657.53 | LossAdj:  0.55180 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     33000 | Loss:    18317.52 | LossAdj:  0.55508 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     34000 | Loss:    18759.91 | LossAdj:  0.55176 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     35000 | Loss:    19290.19 | LossAdj:  0.55115 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     36000 | Loss:    19606.48 | LossAdj:  0.54462 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     37000 | Loss:    20272.33 | LossAdj:  0.54790 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     38000 | Loss:    20671.80 | LossAdj:  0.54399 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:     39000 | Loss:    20881.02 | LossAdj:  0.53541 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:     40000 | Loss:    21285.34 | LossAdj:  0.53213 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:     41000 | Loss:    21719.18 | LossAdj:  0.52974 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:     42000 | Loss:    21954.45 | LossAdj:  0.52272 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:     43000 | Loss:    22386.33 | LossAdj:  0.52061 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:     44000 | Loss:    22803.83 | LossAdj:  0.51827 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:     45000 | Loss:    23373.19 | LossAdj:  0.51940 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:     46000 | Loss:    23746.28 | LossAdj:  0.51622 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:     47000 | Loss:    24077.82 | LossAdj:  0.51229 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:     48000 | Loss:    24711.91 | LossAdj:  0.51483 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:     49000 | Loss:    25141.45 | LossAdj:  0.51309 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:     50000 | Loss:    25519.79 | LossAdj:  0.51040 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:     51000 | Loss:    26020.04 | LossAdj:  0.51020 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:     52000 | Loss:    26598.91 | LossAdj:  0.51152 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:     53000 | Loss:    26978.16 | LossAdj:  0.50902 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:     54000 | Loss:    27277.00 | LossAdj:  0.50513 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:     55000 | Loss:    27643.82 | LossAdj:  0.50261 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:     56000 | Loss:    27997.18 | LossAdj:  0.49995 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:     57000 | Loss:    28688.33 | LossAdj:  0.50330 | Time taken:   32 seconds\n",
      "Epoch:   0 | Training Samples:     58000 | Loss:    29351.87 | LossAdj:  0.50607 | Time taken:   32 seconds\n",
      "Epoch:   0 | Training Samples:     59000 | Loss:    29902.63 | LossAdj:  0.50682 | Time taken:   33 seconds\n",
      "Epoch:   0 | Training Samples:     60000 | Loss:    30281.31 | LossAdj:  0.50469 | Time taken:   33 seconds\n",
      "Epoch:   0 | Training Samples:     61000 | Loss:    30690.72 | LossAdj:  0.50313 | Time taken:   34 seconds\n",
      "Epoch:   0 | Training Samples:     62000 | Loss:    31035.57 | LossAdj:  0.50057 | Time taken:   35 seconds\n",
      "Epoch:   0 | Training Samples:     63000 | Loss:    31442.41 | LossAdj:  0.49909 | Time taken:   35 seconds\n",
      "Epoch:   0 | Training Samples:     64000 | Loss:    32065.53 | LossAdj:  0.50102 | Time taken:   36 seconds\n",
      "Epoch:   0 | Training Samples:     65000 | Loss:    32396.35 | LossAdj:  0.49841 | Time taken:   36 seconds\n",
      "Epoch:   0 | Training Samples:     66000 | Loss:    32811.30 | LossAdj:  0.49714 | Time taken:   37 seconds\n",
      "Epoch:   0 | Training Samples:     67000 | Loss:    33237.75 | LossAdj:  0.49609 | Time taken:   38 seconds\n",
      "Epoch:   0 | Training Samples:     68000 | Loss:    33690.42 | LossAdj:  0.49545 | Time taken:   38 seconds\n",
      "Epoch:   0 | Training Samples:     69000 | Loss:    34015.70 | LossAdj:  0.49298 | Time taken:   39 seconds\n",
      "Epoch:   0 | Training Samples:     70000 | Loss:    34604.21 | LossAdj:  0.49435 | Time taken:   39 seconds\n",
      "Epoch:   0 | Training Samples:     71000 | Loss:    34910.12 | LossAdj:  0.49169 | Time taken:   40 seconds\n",
      "Epoch:   0 | Training Samples:     72000 | Loss:    35370.63 | LossAdj:  0.49126 | Time taken:   41 seconds\n",
      "Epoch:   0 | Training Samples:     73000 | Loss:    35911.17 | LossAdj:  0.49193 | Time taken:   41 seconds\n",
      "Epoch:   0 | Training Samples:     74000 | Loss:    36315.88 | LossAdj:  0.49076 | Time taken:   42 seconds\n",
      "Epoch:   0 | Training Samples:     75000 | Loss:    36748.56 | LossAdj:  0.48998 | Time taken:   42 seconds\n",
      "Epoch:   0 | Training Samples:     76000 | Loss:    37202.95 | LossAdj:  0.48951 | Time taken:   43 seconds\n",
      "Epoch:   0 | Training Samples:     77000 | Loss:    37780.98 | LossAdj:  0.49066 | Time taken:   44 seconds\n",
      "Epoch:   0 | Training Samples:     78000 | Loss:    38210.73 | LossAdj:  0.48988 | Time taken:   44 seconds\n",
      "Epoch:   0 | Training Samples:     79000 | Loss:    38659.35 | LossAdj:  0.48936 | Time taken:   45 seconds\n",
      "Epoch:   0 | Training Samples:     80000 | Loss:    39088.99 | LossAdj:  0.48861 | Time taken:   45 seconds\n",
      "Epoch:   0 | Training Samples:     81000 | Loss:    39425.74 | LossAdj:  0.48674 | Time taken:   46 seconds\n",
      "Epoch:   0 | Training Samples:     82000 | Loss:    39677.90 | LossAdj:  0.48388 | Time taken:   47 seconds\n",
      "Epoch:   0 | Training Samples:     83000 | Loss:    40042.14 | LossAdj:  0.48244 | Time taken:   47 seconds\n",
      "Epoch:   0 | Training Samples:     84000 | Loss:    40479.19 | LossAdj:  0.48190 | Time taken:   48 seconds\n",
      "Epoch:   0 | Training Samples:     85000 | Loss:    41037.21 | LossAdj:  0.48279 | Time taken:   48 seconds\n",
      "Epoch:   0 | Training Samples:     86000 | Loss:    41496.24 | LossAdj:  0.48251 | Time taken:   49 seconds\n",
      "Epoch:   0 | Training Samples:     87000 | Loss:    42045.46 | LossAdj:  0.48328 | Time taken:   49 seconds\n",
      "Epoch:   0 | Training Samples:     88000 | Loss:    42622.88 | LossAdj:  0.48435 | Time taken:   50 seconds\n",
      "Epoch:   0 | Training Samples:     89000 | Loss:    43226.97 | LossAdj:  0.48570 | Time taken:   51 seconds\n",
      "Epoch:   0 | Training Samples:     90000 | Loss:    43817.15 | LossAdj:  0.48686 | Time taken:   51 seconds\n",
      "Epoch:   0 | Training Samples:     91000 | Loss:    44218.01 | LossAdj:  0.48591 | Time taken:   52 seconds\n",
      "Epoch:   0 | Training Samples:     92000 | Loss:    44694.71 | LossAdj:  0.48581 | Time taken:   52 seconds\n",
      "Epoch:   0 | Training Samples:     93000 | Loss:    44980.07 | LossAdj:  0.48366 | Time taken:   53 seconds\n",
      "Epoch:   0 | Training Samples:     94000 | Loss:    45257.12 | LossAdj:  0.48146 | Time taken:   53 seconds\n",
      "Epoch:   0 | Training Samples:     95000 | Loss:    45659.86 | LossAdj:  0.48063 | Time taken:   54 seconds\n",
      "Epoch:   0 | Training Samples:     96000 | Loss:    46299.64 | LossAdj:  0.48229 | Time taken:   55 seconds\n",
      "Epoch:   0 | Training Samples:     97000 | Loss:    46739.96 | LossAdj:  0.48186 | Time taken:   55 seconds\n",
      "Epoch:   0 | Training Samples:     98000 | Loss:    47165.04 | LossAdj:  0.48128 | Time taken:   56 seconds\n",
      "Epoch:   0 | Training Samples:     99000 | Loss:    47482.38 | LossAdj:  0.47962 | Time taken:   56 seconds\n",
      "Epoch:   0 | Training Samples:    100000 | Loss:    47680.76 | LossAdj:  0.47681 | Time taken:   57 seconds\n",
      "Epoch:   0 | Training Samples:    101000 | Loss:    48234.33 | LossAdj:  0.47757 | Time taken:   57 seconds\n",
      "Epoch:   0 | Training Samples:    102000 | Loss:    48709.22 | LossAdj:  0.47754 | Time taken:   58 seconds\n",
      "Epoch:   0 | Training Samples:    103000 | Loss:    49037.14 | LossAdj:  0.47609 | Time taken:   59 seconds\n",
      "Epoch:   0 | Training Samples:    104000 | Loss:    49449.75 | LossAdj:  0.47548 | Time taken:   59 seconds\n",
      "Epoch:   0 | Training Samples:    105000 | Loss:    49803.88 | LossAdj:  0.47432 | Time taken:   60 seconds\n",
      "Epoch:   0 | Training Samples:    106000 | Loss:    50112.19 | LossAdj:  0.47276 | Time taken:   60 seconds\n",
      "Epoch:   0 | Training Samples:    107000 | Loss:    50649.39 | LossAdj:  0.47336 | Time taken:   61 seconds\n",
      "Epoch:   0 | Training Samples:    108000 | Loss:    51156.93 | LossAdj:  0.47368 | Time taken:   61 seconds\n",
      "Epoch:   0 | Training Samples:    109000 | Loss:    51592.43 | LossAdj:  0.47333 | Time taken:   62 seconds\n",
      "Epoch:   0 | Training Samples:    110000 | Loss:    51954.63 | LossAdj:  0.47231 | Time taken:   63 seconds\n",
      "Epoch:   0 | Training Samples:    111000 | Loss:    52335.31 | LossAdj:  0.47149 | Time taken:   63 seconds\n",
      "Epoch:   0 | Training Samples:    112000 | Loss:    52767.08 | LossAdj:  0.47113 | Time taken:   64 seconds\n",
      "Epoch:   0 | Training Samples:    113000 | Loss:    53203.69 | LossAdj:  0.47083 | Time taken:   64 seconds\n",
      "Epoch:   0 | Training Samples:    114000 | Loss:    53480.39 | LossAdj:  0.46913 | Time taken:   65 seconds\n",
      "Epoch:   0 | Training Samples:    115000 | Loss:    53911.85 | LossAdj:  0.46880 | Time taken:   65 seconds\n",
      "Epoch:   0 | Training Samples:    116000 | Loss:    54481.56 | LossAdj:  0.46967 | Time taken:   66 seconds\n",
      "Epoch:   0 | Training Samples:    117000 | Loss:    54888.32 | LossAdj:  0.46913 | Time taken:   67 seconds\n",
      "Epoch:   0 | Training Samples:    118000 | Loss:    55293.53 | LossAdj:  0.46859 | Time taken:   67 seconds\n",
      "Epoch:   0 | Training Samples:    119000 | Loss:    55767.51 | LossAdj:  0.46863 | Time taken:   68 seconds\n",
      "Epoch:   0 | Training Samples:    120000 | Loss:    56412.18 | LossAdj:  0.47010 | Time taken:   68 seconds\n",
      "Epoch:   0 | Training Samples:    121000 | Loss:    56783.45 | LossAdj:  0.46928 | Time taken:   69 seconds\n",
      "Epoch:   0 | Training Samples:    122000 | Loss:    57315.33 | LossAdj:  0.46980 | Time taken:   70 seconds\n",
      "Epoch:   0 | Training Samples:    123000 | Loss:    57801.33 | LossAdj:  0.46993 | Time taken:   70 seconds\n",
      "Epoch:   0 | Training Samples:    124000 | Loss:    58230.60 | LossAdj:  0.46960 | Time taken:   71 seconds\n",
      "Epoch:   0 | Training Samples:    125000 | Loss:    58561.44 | LossAdj:  0.46849 | Time taken:   71 seconds\n",
      "Epoch:   0 | Training Samples:    126000 | Loss:    59023.23 | LossAdj:  0.46844 | Time taken:   72 seconds\n",
      "Epoch:   0 | Training Samples:    127000 | Loss:    59465.08 | LossAdj:  0.46823 | Time taken:   73 seconds\n",
      "Epoch:   0 | Training Samples:    128000 | Loss:    60033.85 | LossAdj:  0.46901 | Time taken:   73 seconds\n",
      "Epoch:   0 | Training Samples:    129000 | Loss:    60341.89 | LossAdj:  0.46777 | Time taken:   74 seconds\n",
      "Epoch:   0 | Training Samples:    130000 | Loss:    60526.91 | LossAdj:  0.46559 | Time taken:   74 seconds\n",
      "Epoch:   0 | Training Samples:    131000 | Loss:    60888.07 | LossAdj:  0.46479 | Time taken:   75 seconds\n",
      "Epoch:   0 | Training Samples:    132000 | Loss:    61388.89 | LossAdj:  0.46507 | Time taken:   75 seconds\n",
      "Epoch:   0 | Training Samples:    133000 | Loss:    61743.22 | LossAdj:  0.46423 | Time taken:   76 seconds\n",
      "Epoch:   0 | Training Samples:    134000 | Loss:    62132.27 | LossAdj:  0.46367 | Time taken:   77 seconds\n",
      "Epoch:   0 | Training Samples:    135000 | Loss:    62711.31 | LossAdj:  0.46453 | Time taken:   77 seconds\n",
      "Epoch:   0 | Training Samples:    136000 | Loss:    63204.01 | LossAdj:  0.46474 | Time taken:   78 seconds\n",
      "Epoch:   0 | Training Samples:    137000 | Loss:    63495.84 | LossAdj:  0.46347 | Time taken:   78 seconds\n",
      "Epoch:   0 | Training Samples:    138000 | Loss:    63965.98 | LossAdj:  0.46352 | Time taken:   79 seconds\n",
      "Epoch:   0 | Training Samples:    139000 | Loss:    64398.76 | LossAdj:  0.46330 | Time taken:   79 seconds\n",
      "Epoch:   0 | Training Samples:    140000 | Loss:    64865.07 | LossAdj:  0.46332 | Time taken:   80 seconds\n",
      "Epoch:   0 | Training Samples:    141000 | Loss:    65246.32 | LossAdj:  0.46274 | Time taken:   80 seconds\n",
      "Epoch:   0 | Training Samples:    142000 | Loss:    65598.68 | LossAdj:  0.46196 | Time taken:   81 seconds\n",
      "Epoch:   0 | Training Samples:    143000 | Loss:    65900.02 | LossAdj:  0.46084 | Time taken:   82 seconds\n",
      "Epoch:   0 | Training Samples:    144000 | Loss:    66483.19 | LossAdj:  0.46169 | Time taken:   82 seconds\n",
      "Epoch:   0 | Training Samples:    145000 | Loss:    67193.78 | LossAdj:  0.46341 | Time taken:   83 seconds\n",
      "Epoch:   0 | Training Samples:    146000 | Loss:    67543.41 | LossAdj:  0.46263 | Time taken:   83 seconds\n",
      "Epoch:   0 | Training Samples:    147000 | Loss:    67869.03 | LossAdj:  0.46169 | Time taken:   84 seconds\n",
      "Epoch:   0 | Training Samples:    148000 | Loss:    68402.78 | LossAdj:  0.46218 | Time taken:   84 seconds\n",
      "Epoch:   0 | Training Samples:    149000 | Loss:    68961.32 | LossAdj:  0.46283 | Time taken:   85 seconds\n",
      "Epoch:   0 | Training Samples:    150000 | Loss:    69501.21 | LossAdj:  0.46334 | Time taken:   85 seconds\n",
      " --- TRAINING FINISHED IN 85 SECONDS WITH LOSS 0.46 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97     45786\n",
      "           1       0.68      0.88      0.77      4214\n",
      "\n",
      "    accuracy                           0.95     50000\n",
      "   macro avg       0.83      0.92      0.87     50000\n",
      "weighted avg       0.96      0.95      0.96     50000\n",
      "\n",
      "AUC = 0.963656\n",
      "Epoch:   0 | Training Samples:      1000 | Loss:     1257.57 | LossAdj:  1.25757 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      2000 | Loss:     2112.75 | LossAdj:  1.05637 | Time taken:    0 seconds\n",
      "Epoch:   0 | Training Samples:      3000 | Loss:     2993.43 | LossAdj:  0.99781 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      4000 | Loss:     3922.74 | LossAdj:  0.98068 | Time taken:    1 seconds\n",
      "Epoch:   0 | Training Samples:      5000 | Loss:     5088.32 | LossAdj:  1.01766 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:      6000 | Loss:     5995.98 | LossAdj:  0.99933 | Time taken:    2 seconds\n",
      "Epoch:   0 | Training Samples:      7000 | Loss:     7110.94 | LossAdj:  1.01585 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:      8000 | Loss:     8156.98 | LossAdj:  1.01962 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:      9000 | Loss:     9001.04 | LossAdj:  1.00012 | Time taken:    3 seconds\n",
      "Epoch:   0 | Training Samples:     10000 | Loss:    10078.24 | LossAdj:  1.00782 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     11000 | Loss:    11177.21 | LossAdj:  1.01611 | Time taken:    4 seconds\n",
      "Epoch:   0 | Training Samples:     12000 | Loss:    12171.60 | LossAdj:  1.01430 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     13000 | Loss:    13394.17 | LossAdj:  1.03032 | Time taken:    5 seconds\n",
      "Epoch:   0 | Training Samples:     14000 | Loss:    14323.12 | LossAdj:  1.02308 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     15000 | Loss:    14942.94 | LossAdj:  0.99620 | Time taken:    6 seconds\n",
      "Epoch:   0 | Training Samples:     16000 | Loss:    16090.88 | LossAdj:  1.00568 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     17000 | Loss:    16988.05 | LossAdj:  0.99930 | Time taken:    7 seconds\n",
      "Epoch:   0 | Training Samples:     18000 | Loss:    18004.15 | LossAdj:  1.00023 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     19000 | Loss:    18904.84 | LossAdj:  0.99499 | Time taken:    8 seconds\n",
      "Epoch:   0 | Training Samples:     20000 | Loss:    19981.50 | LossAdj:  0.99908 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     21000 | Loss:    21207.77 | LossAdj:  1.00989 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     22000 | Loss:    22482.16 | LossAdj:  1.02192 | Time taken:    9 seconds\n",
      "Epoch:   0 | Training Samples:     23000 | Loss:    23362.86 | LossAdj:  1.01578 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     24000 | Loss:    24191.96 | LossAdj:  1.00800 | Time taken:   10 seconds\n",
      "Epoch:   0 | Training Samples:     25000 | Loss:    24924.61 | LossAdj:  0.99698 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     26000 | Loss:    26015.79 | LossAdj:  1.00061 | Time taken:   11 seconds\n",
      "Epoch:   0 | Training Samples:     27000 | Loss:    26783.98 | LossAdj:  0.99200 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     28000 | Loss:    27646.95 | LossAdj:  0.98739 | Time taken:   12 seconds\n",
      "Epoch:   0 | Training Samples:     29000 | Loss:    28376.89 | LossAdj:  0.97851 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     30000 | Loss:    29228.78 | LossAdj:  0.97429 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     31000 | Loss:    30210.54 | LossAdj:  0.97453 | Time taken:   13 seconds\n",
      "Epoch:   0 | Training Samples:     32000 | Loss:    30822.37 | LossAdj:  0.96320 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     33000 | Loss:    32029.66 | LossAdj:  0.97060 | Time taken:   14 seconds\n",
      "Epoch:   0 | Training Samples:     34000 | Loss:    33289.04 | LossAdj:  0.97909 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     35000 | Loss:    34255.27 | LossAdj:  0.97872 | Time taken:   15 seconds\n",
      "Epoch:   0 | Training Samples:     36000 | Loss:    35003.99 | LossAdj:  0.97233 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     37000 | Loss:    35706.04 | LossAdj:  0.96503 | Time taken:   16 seconds\n",
      "Epoch:   0 | Training Samples:     38000 | Loss:    36680.91 | LossAdj:  0.96529 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     39000 | Loss:    37258.07 | LossAdj:  0.95534 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     40000 | Loss:    37940.05 | LossAdj:  0.94850 | Time taken:   17 seconds\n",
      "Epoch:   0 | Training Samples:     41000 | Loss:    38860.91 | LossAdj:  0.94783 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     42000 | Loss:    39667.87 | LossAdj:  0.94447 | Time taken:   18 seconds\n",
      "Epoch:   0 | Training Samples:     43000 | Loss:    40426.38 | LossAdj:  0.94015 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     44000 | Loss:    41325.41 | LossAdj:  0.93921 | Time taken:   19 seconds\n",
      "Epoch:   0 | Training Samples:     45000 | Loss:    42282.13 | LossAdj:  0.93960 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     46000 | Loss:    43045.49 | LossAdj:  0.93577 | Time taken:   20 seconds\n",
      "Epoch:   0 | Training Samples:     47000 | Loss:    44070.65 | LossAdj:  0.93767 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:     48000 | Loss:    45305.59 | LossAdj:  0.94387 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:     49000 | Loss:    46459.40 | LossAdj:  0.94815 | Time taken:   21 seconds\n",
      "Epoch:   0 | Training Samples:     50000 | Loss:    47507.75 | LossAdj:  0.95015 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:     51000 | Loss:    48207.39 | LossAdj:  0.94524 | Time taken:   22 seconds\n",
      "Epoch:   0 | Training Samples:     52000 | Loss:    48813.61 | LossAdj:  0.93872 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:     53000 | Loss:    49551.49 | LossAdj:  0.93493 | Time taken:   23 seconds\n",
      "Epoch:   0 | Training Samples:     54000 | Loss:    50318.73 | LossAdj:  0.93183 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:     55000 | Loss:    51146.89 | LossAdj:  0.92994 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:     56000 | Loss:    52061.12 | LossAdj:  0.92966 | Time taken:   24 seconds\n",
      "Epoch:   0 | Training Samples:     57000 | Loss:    52705.46 | LossAdj:  0.92466 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:     58000 | Loss:    53390.88 | LossAdj:  0.92053 | Time taken:   25 seconds\n",
      "Epoch:   0 | Training Samples:     59000 | Loss:    54059.54 | LossAdj:  0.91626 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:     60000 | Loss:    55178.80 | LossAdj:  0.91965 | Time taken:   26 seconds\n",
      "Epoch:   0 | Training Samples:     61000 | Loss:    55870.49 | LossAdj:  0.91591 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:     62000 | Loss:    56644.42 | LossAdj:  0.91362 | Time taken:   27 seconds\n",
      "Epoch:   0 | Training Samples:     63000 | Loss:    57705.42 | LossAdj:  0.91596 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:     64000 | Loss:    58970.33 | LossAdj:  0.92141 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:     65000 | Loss:    60195.57 | LossAdj:  0.92609 | Time taken:   28 seconds\n",
      "Epoch:   0 | Training Samples:     66000 | Loss:    61377.78 | LossAdj:  0.92997 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:     67000 | Loss:    62111.35 | LossAdj:  0.92704 | Time taken:   29 seconds\n",
      "Epoch:   0 | Training Samples:     68000 | Loss:    63504.42 | LossAdj:  0.93389 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:     69000 | Loss:    64852.09 | LossAdj:  0.93989 | Time taken:   30 seconds\n",
      "Epoch:   0 | Training Samples:     70000 | Loss:    65601.76 | LossAdj:  0.93717 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:     71000 | Loss:    66242.42 | LossAdj:  0.93299 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:     72000 | Loss:    66937.99 | LossAdj:  0.92969 | Time taken:   31 seconds\n",
      "Epoch:   0 | Training Samples:     73000 | Loss:    68138.61 | LossAdj:  0.93341 | Time taken:   32 seconds\n",
      "Epoch:   0 | Training Samples:     74000 | Loss:    68886.27 | LossAdj:  0.93090 | Time taken:   32 seconds\n",
      "Epoch:   0 | Training Samples:     75000 | Loss:    69900.55 | LossAdj:  0.93201 | Time taken:   33 seconds\n",
      "Epoch:   0 | Training Samples:     76000 | Loss:    70842.98 | LossAdj:  0.93214 | Time taken:   33 seconds\n",
      "Epoch:   0 | Training Samples:     77000 | Loss:    71483.82 | LossAdj:  0.92836 | Time taken:   34 seconds\n",
      "Epoch:   0 | Training Samples:     78000 | Loss:    72154.74 | LossAdj:  0.92506 | Time taken:   34 seconds\n",
      "Epoch:   0 | Training Samples:     79000 | Loss:    73012.41 | LossAdj:  0.92421 | Time taken:   34 seconds\n",
      "Epoch:   0 | Training Samples:     80000 | Loss:    74440.91 | LossAdj:  0.93051 | Time taken:   35 seconds\n",
      "Epoch:   0 | Training Samples:     81000 | Loss:    75418.48 | LossAdj:  0.93109 | Time taken:   35 seconds\n",
      "Epoch:   0 | Training Samples:     82000 | Loss:    76294.89 | LossAdj:  0.93043 | Time taken:   36 seconds\n",
      "Epoch:   0 | Training Samples:     83000 | Loss:    77157.43 | LossAdj:  0.92961 | Time taken:   36 seconds\n",
      "Epoch:   0 | Training Samples:     84000 | Loss:    77970.58 | LossAdj:  0.92822 | Time taken:   37 seconds\n",
      "Epoch:   0 | Training Samples:     85000 | Loss:    78426.28 | LossAdj:  0.92266 | Time taken:   37 seconds\n",
      "Epoch:   0 | Training Samples:     86000 | Loss:    79520.20 | LossAdj:  0.92465 | Time taken:   37 seconds\n",
      "Epoch:   0 | Training Samples:     87000 | Loss:    80307.06 | LossAdj:  0.92307 | Time taken:   38 seconds\n",
      "Epoch:   0 | Training Samples:     88000 | Loss:    80786.82 | LossAdj:  0.91803 | Time taken:   38 seconds\n",
      "Epoch:   0 | Training Samples:     89000 | Loss:    81672.57 | LossAdj:  0.91767 | Time taken:   39 seconds\n",
      "Epoch:   0 | Training Samples:     90000 | Loss:    83088.54 | LossAdj:  0.92321 | Time taken:   39 seconds\n",
      "Epoch:   0 | Training Samples:     91000 | Loss:    84763.46 | LossAdj:  0.93147 | Time taken:   40 seconds\n",
      "Epoch:   0 | Training Samples:     92000 | Loss:    85629.42 | LossAdj:  0.93075 | Time taken:   40 seconds\n",
      "Epoch:   0 | Training Samples:     93000 | Loss:    86275.04 | LossAdj:  0.92769 | Time taken:   40 seconds\n",
      "Epoch:   0 | Training Samples:     94000 | Loss:    86918.13 | LossAdj:  0.92466 | Time taken:   41 seconds\n",
      "Epoch:   0 | Training Samples:     95000 | Loss:    87656.31 | LossAdj:  0.92270 | Time taken:   41 seconds\n",
      "Epoch:   0 | Training Samples:     96000 | Loss:    88541.03 | LossAdj:  0.92230 | Time taken:   42 seconds\n",
      "Epoch:   0 | Training Samples:     97000 | Loss:    89605.20 | LossAdj:  0.92376 | Time taken:   42 seconds\n",
      "Epoch:   0 | Training Samples:     98000 | Loss:    90917.31 | LossAdj:  0.92773 | Time taken:   42 seconds\n",
      "Epoch:   0 | Training Samples:     99000 | Loss:    91771.78 | LossAdj:  0.92699 | Time taken:   43 seconds\n",
      "Epoch:   0 | Training Samples:    100000 | Loss:    92744.42 | LossAdj:  0.92744 | Time taken:   43 seconds\n",
      "Epoch:   0 | Training Samples:    101000 | Loss:    93969.04 | LossAdj:  0.93039 | Time taken:   44 seconds\n",
      "Epoch:   0 | Training Samples:    102000 | Loss:    94463.27 | LossAdj:  0.92611 | Time taken:   44 seconds\n",
      "Epoch:   0 | Training Samples:    103000 | Loss:    95752.45 | LossAdj:  0.92964 | Time taken:   45 seconds\n",
      "Epoch:   0 | Training Samples:    104000 | Loss:    96390.35 | LossAdj:  0.92683 | Time taken:   45 seconds\n",
      "Epoch:   0 | Training Samples:    105000 | Loss:    97190.71 | LossAdj:  0.92563 | Time taken:   45 seconds\n",
      "Epoch:   0 | Training Samples:    106000 | Loss:    98215.18 | LossAdj:  0.92656 | Time taken:   46 seconds\n",
      "Epoch:   0 | Training Samples:    107000 | Loss:    98900.67 | LossAdj:  0.92431 | Time taken:   46 seconds\n",
      "Epoch:   0 | Training Samples:    108000 | Loss:    99735.78 | LossAdj:  0.92348 | Time taken:   47 seconds\n",
      "Epoch:   0 | Training Samples:    109000 | Loss:   101027.22 | LossAdj:  0.92686 | Time taken:   47 seconds\n",
      "Epoch:   0 | Training Samples:    110000 | Loss:   101753.20 | LossAdj:  0.92503 | Time taken:   48 seconds\n",
      "Epoch:   0 | Training Samples:    111000 | Loss:   102688.48 | LossAdj:  0.92512 | Time taken:   48 seconds\n",
      "Epoch:   0 | Training Samples:    112000 | Loss:   103524.09 | LossAdj:  0.92432 | Time taken:   49 seconds\n",
      "Epoch:   0 | Training Samples:    113000 | Loss:   104823.08 | LossAdj:  0.92764 | Time taken:   49 seconds\n",
      "Epoch:   0 | Training Samples:    114000 | Loss:   105424.51 | LossAdj:  0.92478 | Time taken:   49 seconds\n",
      "Epoch:   0 | Training Samples:    115000 | Loss:   106426.80 | LossAdj:  0.92545 | Time taken:   50 seconds\n",
      "Epoch:   0 | Training Samples:    116000 | Loss:   107188.28 | LossAdj:  0.92404 | Time taken:   50 seconds\n",
      "Epoch:   0 | Training Samples:    117000 | Loss:   108603.67 | LossAdj:  0.92824 | Time taken:   51 seconds\n",
      "Epoch:   0 | Training Samples:    118000 | Loss:   109673.32 | LossAdj:  0.92943 | Time taken:   51 seconds\n",
      "Epoch:   0 | Training Samples:    119000 | Loss:   110869.72 | LossAdj:  0.93168 | Time taken:   52 seconds\n",
      "Epoch:   0 | Training Samples:    120000 | Loss:   111506.35 | LossAdj:  0.92922 | Time taken:   52 seconds\n",
      "Epoch:   0 | Training Samples:    121000 | Loss:   112116.66 | LossAdj:  0.92658 | Time taken:   53 seconds\n",
      "Epoch:   0 | Training Samples:    122000 | Loss:   112906.72 | LossAdj:  0.92546 | Time taken:   53 seconds\n",
      "Epoch:   0 | Training Samples:    123000 | Loss:   114101.98 | LossAdj:  0.92766 | Time taken:   54 seconds\n",
      "Epoch:   0 | Training Samples:    124000 | Loss:   115055.00 | LossAdj:  0.92786 | Time taken:   54 seconds\n",
      "Epoch:   0 | Training Samples:    125000 | Loss:   116074.96 | LossAdj:  0.92860 | Time taken:   54 seconds\n",
      "Epoch:   0 | Training Samples:    126000 | Loss:   116790.69 | LossAdj:  0.92691 | Time taken:   55 seconds\n",
      "Epoch:   0 | Training Samples:    127000 | Loss:   117436.62 | LossAdj:  0.92470 | Time taken:   55 seconds\n",
      "Epoch:   0 | Training Samples:    128000 | Loss:   118342.75 | LossAdj:  0.92455 | Time taken:   56 seconds\n",
      "Epoch:   0 | Training Samples:    129000 | Loss:   119441.61 | LossAdj:  0.92590 | Time taken:   56 seconds\n",
      "Epoch:   0 | Training Samples:    130000 | Loss:   120179.34 | LossAdj:  0.92446 | Time taken:   57 seconds\n",
      "Epoch:   0 | Training Samples:    131000 | Loss:   120722.99 | LossAdj:  0.92155 | Time taken:   57 seconds\n",
      "Epoch:   0 | Training Samples:    132000 | Loss:   121762.82 | LossAdj:  0.92245 | Time taken:   57 seconds\n",
      "Epoch:   0 | Training Samples:    133000 | Loss:   123170.46 | LossAdj:  0.92609 | Time taken:   58 seconds\n",
      "Epoch:   0 | Training Samples:    134000 | Loss:   123758.02 | LossAdj:  0.92357 | Time taken:   58 seconds\n",
      "Epoch:   0 | Training Samples:    135000 | Loss:   125366.03 | LossAdj:  0.92864 | Time taken:   59 seconds\n",
      "Epoch:   0 | Training Samples:    136000 | Loss:   125886.07 | LossAdj:  0.92563 | Time taken:   59 seconds\n",
      "Epoch:   0 | Training Samples:    137000 | Loss:   127142.53 | LossAdj:  0.92805 | Time taken:   60 seconds\n",
      "Epoch:   0 | Training Samples:    138000 | Loss:   127784.96 | LossAdj:  0.92598 | Time taken:   60 seconds\n",
      "Epoch:   0 | Training Samples:    139000 | Loss:   128407.45 | LossAdj:  0.92379 | Time taken:   60 seconds\n",
      "Epoch:   0 | Training Samples:    140000 | Loss:   129070.45 | LossAdj:  0.92193 | Time taken:   61 seconds\n",
      "Epoch:   0 | Training Samples:    141000 | Loss:   129857.51 | LossAdj:  0.92098 | Time taken:   61 seconds\n",
      "Epoch:   0 | Training Samples:    142000 | Loss:   131083.36 | LossAdj:  0.92312 | Time taken:   62 seconds\n",
      "Epoch:   0 | Training Samples:    143000 | Loss:   131600.55 | LossAdj:  0.92028 | Time taken:   62 seconds\n",
      "Epoch:   0 | Training Samples:    144000 | Loss:   132075.63 | LossAdj:  0.91719 | Time taken:   63 seconds\n",
      "Epoch:   0 | Training Samples:    145000 | Loss:   133875.26 | LossAdj:  0.92328 | Time taken:   63 seconds\n",
      "Epoch:   0 | Training Samples:    146000 | Loss:   135101.30 | LossAdj:  0.92535 | Time taken:   63 seconds\n",
      "Epoch:   0 | Training Samples:    147000 | Loss:   136453.21 | LossAdj:  0.92825 | Time taken:   64 seconds\n",
      "Epoch:   0 | Training Samples:    148000 | Loss:   137657.81 | LossAdj:  0.93012 | Time taken:   64 seconds\n",
      "Epoch:   0 | Training Samples:    149000 | Loss:   138492.22 | LossAdj:  0.92948 | Time taken:   65 seconds\n",
      "Epoch:   0 | Training Samples:    150000 | Loss:   139432.42 | LossAdj:  0.92955 | Time taken:   65 seconds\n",
      " --- TRAINING FINISHED IN 65 SECONDS WITH LOSS 0.93 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     45786\n",
      "           1       0.72      0.84      0.78      4214\n",
      "\n",
      "    accuracy                           0.96     50000\n",
      "   macro avg       0.85      0.91      0.88     50000\n",
      "weighted avg       0.96      0.96      0.96     50000\n",
      "\n",
      "AUC = 0.955793\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Logloss\")\n",
    "\n",
    "bx = fig.add_subplot(1, 2, 2)\n",
    "bx.grid()\n",
    "bx.set_xlabel(\"False positive rate\")\n",
    "bx.set_ylabel(\"True positive rate\")\n",
    "\n",
    "for idx, lr in enumerate(models):\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    ax.plot(lr.train_tracker_.loss_, color=colors[idx], label=labels[idx])\n",
    "\n",
    "    y_test_prob = lr.raw_predict(X_test)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    print(\"AUC = %f\" % roc_auc)\n",
    "\n",
    "    bx.plot(fpr, tpr, color=colors[idx], label='{0} ROC area = {1:.2f}'.format(labels[idx], roc_auc))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
